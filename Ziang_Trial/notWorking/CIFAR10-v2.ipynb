{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CIFAR10-v2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"code","metadata":{"id":"bjoZY0eX7e2t","executionInfo":{"status":"ok","timestamp":1638821965963,"user_tz":300,"elapsed":165,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["from __future__ import print_function\n","import argparse\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.data import DataLoader\n","from torchsummary import summary\n","import matplotlib.pyplot as plt"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjmZSCZFXn1_","executionInfo":{"status":"ok","timestamp":1638821966116,"user_tz":300,"elapsed":4,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}},"outputId":"12e4086f-6204-4b32-f186-63de19f15bd7"},"source":["print(torch.__version__)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["1.10.0+cu111\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZQKjQICDpXI_"},"source":["### Download the dataset before."]},{"cell_type":"code","metadata":{"id":"jYruD2KdpJ4A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638821968097,"user_tz":300,"elapsed":1983,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}},"outputId":"3a537a0c-226d-4705-8d36-49b80c4c6c0b"},"source":["import torchvision\n","import torch\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","batch_size = 4\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","metadata":{"id":"Ivfl2PtkXPEY","executionInfo":{"status":"ok","timestamp":1638821968098,"user_tz":300,"elapsed":9,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["evens = list(range(0, len(trainset), 2))\n","odds = list(range(1, len(trainset), 2))\n","trainset_1 = torch.utils.data.Subset(trainset, evens)\n","trainset_2 = torch.utils.data.Subset(trainset, odds)\n","\n","trainloader_1 = torch.utils.data.DataLoader(trainset_1, batch_size=4,\n","                                            shuffle=True, num_workers=2)\n","trainloader_2 = torch.utils.data.DataLoader(trainset_2, batch_size=4,\n","                                            shuffle=True, num_workers=2)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"fl5gLQWBXRZl","executionInfo":{"status":"ok","timestamp":1638821968098,"user_tz":300,"elapsed":6,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["dataset1 = trainset\n","dataset2 = testset"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R-wCJ5Wjzavp"},"source":["### Prepare Simple or simple-ResNet Architecture"]},{"cell_type":"code","metadata":{"id":"owzBT2o3XcSQ","executionInfo":{"status":"ok","timestamp":1638821968099,"user_tz":300,"elapsed":6,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1) # flatten all dimensions except batch\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3k4IwsaMvU6k"},"source":["#### Version 1"]},{"cell_type":"code","metadata":{"id":"myRizeCk7c2H","executionInfo":{"status":"ok","timestamp":1638821968099,"user_tz":300,"elapsed":6,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["## version 2\n","class ResidualBlock(nn.Module):\n","    \"\"\"Following the structure of the one implemented in\n","    https://arxiv.org/pdf/1806.10909.pdf\n","    \"\"\"\n","    def __init__(self, data_dim, hidden_dim):\n","        super(ResidualBlock, self).__init__()\n","        self.data_dim = data_dim\n","        self.hidden_dim = hidden_dim\n","\n","        self.mlp = nn.Sequential(\n","            nn.Conv2d(data_dim, data_dim, kernel_size=3),\n","            nn.Linear(data_dim, hidden_dim),\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(32),\n","            nn.Linear(hidden_dim, data_dim),\n","            nn.ReLU(True)\n","        )\n","\n","    def forward(self, x):\n","        return x + self.mlp(x)\n","\n","\n","class ResNet(nn.Module):\n","    \"\"\"ResNet which maps data_dim dimensional points to an output_dim\n","    dimensional output.\n","    \"\"\"\n","# ResNet(data_dim = 28*28*1, hidden_dim = 128 , num_layers = 5, output_dim=10, is_img=True)\n","\n","    def __init__(self, data_dim, hidden_dim, num_layers, output_dim=1,\n","                 is_img=False):\n","        super(ResNet, self).__init__()\n","        residual_blocks = \\\n","            [ResidualBlock(data_dim, hidden_dim) for _ in range(num_layers)]\n","        self.residual_blocks = nn.Sequential(*residual_blocks)\n","        self.linear_layer = nn.Linear(data_dim, output_dim)\n","        self.num_layers = num_layers\n","        self.output_dim = output_dim\n","        self.is_img = is_img\n","\n","    def forward(self, x, return_features=False):\n","        if self.is_img:\n","            # Flatten image, i.e. (batch_size, channels, height, width) to\n","            # (batch_size, channels * height * width)\n","            features = self.residual_blocks(x.view(x.size(0), -1))\n","        else:\n","            features = self.residual_blocks(x)\n","        pred = self.linear_layer(features)\n","        if return_features:\n","            return features, pred\n","        return pred\n","\n","    def hidden_dim(self):\n","        return self.residual_blocks.hidden_dim\n","\n","class MLPNet(nn.Module):\n","    \"\"\"\n","    \"\"\"\n","    def __init__(self, data_dim, hidden_dim):\n","        super(MLPNet, self).__init__()\n","        self.data_dim = data_dim\n","        self.hidden_dim = hidden_dim\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(data_dim, hidden_dim),\n","            nn.ReLU(True),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.ReLU(True),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","    def forward(self, x):\n","        return self.mlp(x)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g8DCoHqACXpN"},"source":["#### Previous of our model's dimension \n","doubl-check on our architecture and develop a feeling of how many parameters we are going to train"]},{"cell_type":"code","metadata":{"id":"mpeIwhhGXsre","executionInfo":{"status":"ok","timestamp":1638821970740,"user_tz":300,"elapsed":2646,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["for data, target in dataset2:\n","  pass\n","x = data.shape"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oUqei4r9YBWk","executionInfo":{"status":"ok","timestamp":1638821970741,"user_tz":300,"elapsed":14,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}},"outputId":"b8a4dae5-f635-48e1-e4bd-19b11183e013"},"source":["print(x)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 32, 32])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eV6306LvYVJ8","executionInfo":{"status":"ok","timestamp":1638821970741,"user_tz":300,"elapsed":12,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}},"outputId":"c71ea921-5eb7-4d49-c96c-f39228603d85"},"source":["from torchsummary import summary\n","# model = ResNet(data_dim = 32*32*3, hidden_dim = 128 , num_layers = 5, output_dim=10, is_img=True)\n","model = Net()\n","if torch.cuda.is_available():\n","    model.cuda()\n","summary(model,(3,32,32))"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 6, 28, 28]             456\n","         MaxPool2d-2            [-1, 6, 14, 14]               0\n","            Conv2d-3           [-1, 16, 10, 10]           2,416\n","         MaxPool2d-4             [-1, 16, 5, 5]               0\n","            Linear-5                  [-1, 120]          48,120\n","            Linear-6                   [-1, 84]          10,164\n","            Linear-7                   [-1, 10]             850\n","================================================================\n","Total params: 62,006\n","Trainable params: 62,006\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 0.06\n","Params size (MB): 0.24\n","Estimated Total Size (MB): 0.31\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"foUB27ZDyTT-"},"source":["#### Define train & test methods\n"]},{"cell_type":"code","metadata":{"id":"yZnTwxmB7oFY","executionInfo":{"status":"ok","timestamp":1638821970741,"user_tz":300,"elapsed":5,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["def test(trainer, model, device, test_loader, epoch):\n","    model.eval()\n","\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    # print('\\nTest set: Epoch: {} Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","    #     epoch, test_loss, correct, len(test_loader.dataset),\n","    #     (100. * round(correct / len(test_loader.dataset), 6)))\n","    \n","    trainer.accuracy_list.append(100. * round(correct / len(test_loader.dataset), 6))\n","    trainer.loss_list.append(test_loss)\n","    "],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4F1Sq3_0u4G","executionInfo":{"status":"ok","timestamp":1638821970742,"user_tz":300,"elapsed":5,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["import json\n","import torch.nn as nn\n","from numpy import mean\n","\n","\n","class Trainer():\n","    \"\"\"Class used to train ODENets, ConvODENets and ResNets.\n","    Parameters\n","    ----------\n","    model : one of models.ODENet, conv_models.ConvODENet, discrete_models.ResNet\n","    optimizer : torch.optim.Optimizer instance\n","    device : torch.device\n","    classification : bool\n","        If True, trains a classification model with cross entropy loss,\n","        otherwise trains a regression model with Huber loss.\n","    print_freq : int\n","        Frequency with which to print information (loss, nfes etc).\n","    record_freq : int\n","        Frequency with which to record information (loss, nfes etc).\n","    verbose : bool\n","        If True prints information (loss, nfes etc) during training.\n","    save_dir : None or tuple of string and string\n","        If not None, saves losses and nfes (for ode models) to directory\n","        specified by the first string with id specified by the second string.\n","        This is useful for training models when underflow in the time step or\n","        excessively large NFEs may occur.\n","    \"\"\"\n","    def __init__(self, model, optimizer, device, classification=False,\n","                 print_freq=2000, record_freq=2000, verbose=False, save_dir=None):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.classification = classification\n","        self.device = device\n","        if self.classification:\n","            self.loss_func = nn.CrossEntropyLoss()\n","        else:\n","            self.loss_func = nn.SmoothL1Loss()\n","        self.print_freq = print_freq\n","        self.record_freq = record_freq\n","        self.steps = 0\n","        self.save_dir = save_dir\n","        self.verbose = verbose\n","\n","        self.histories = {'loss_history': [], 'nfe_history': [],\n","                          'bnfe_history': [], 'total_nfe_history': [],\n","                          'epoch_loss_history': [], 'epoch_nfe_history': [],\n","                          'epoch_bnfe_history': [], 'epoch_total_nfe_history': []}\n","        self.buffer = {'loss': [], 'nfe': [], 'bnfe': [], 'total_nfe': []}\n","\n","        # Only resnets have a number of layers attribute\n","        self.is_resnet = hasattr(self.model, 'num_layers')\n","\n","        # Lists for visualization of loss and accuracy \n","        self.loss_list = []\n","        self.iteration_list = []\n","        self.accuracy_list = []\n","        self.avg_loss_list = []\n","\n","\n","        # Lists for knowing classwise accuracy\n","        self.predictions_list = []\n","        self.labels_list = []\n","\n","\n","    def train(self, data_loader, num_epochs, device, test_loader):\n","        \"\"\"Trains model on data in data_loader for num_epochs.\n","        Parameters\n","        ----------\n","        data_loader : torch.utils.data.DataLoader\n","        num_epochs : int\n","        \"\"\"\n","        for epoch in range(num_epochs):\n","            avg_loss = self._train_epoch(data_loader)\n","\n","            self.iteration_list.append(epoch)\n","            self.avg_loss_list.append(round(avg_loss,6))\n","\n","            if self.verbose:\n","                print(\"Epoch {}: {:.3f}\".format(epoch + 1, avg_loss))\n","                \n","            test(self, self.model, self.device, test_loader, epoch)\n","\n","            if (epoch+1 == num_epochs):\n","              print('\\nTest set: Epoch: {} Average Test loss: {:.4f}, Accuracy: ({:.4f}%)\\n'.format(\n","                epoch+1, self.loss_list[-1], self.accuracy_list[-1]))\n","        \n","        plt.plot(self.iteration_list, self.loss_list)\n","        plt.xlabel(\"No. of Iteration\")\n","        plt.ylabel(\"Loss\")\n","        plt.title(\"Iterations vs Test Loss\")\n","        plt.show()\n","\n","        plt.plot(self.iteration_list, self.accuracy_list)\n","        plt.xlabel(\"No. of Iteration\")\n","        plt.ylabel(\"Accuracy\")\n","        plt.title(\"Iterations vs Test Accuracy\")\n","        plt.show()\n","\n","        plt.plot(self.iteration_list, self.avg_loss_list)\n","        plt.xlabel(\"No. of Iteration\")\n","        plt.ylabel(\"Accuracy\")\n","        plt.title(\"Iterations vs Traning avg_loss\")\n","        plt.show()\n","\n","    def _train_epoch(self, data_loader):\n","        \"\"\"Trains model for an epoch.\n","        Parameters\n","        ----------\n","        data_loader : torch.utils.data.DataLoader\n","        \"\"\"\n","        epoch_loss = 0.\n","        epoch_nfes = 0\n","        epoch_backward_nfes = 0\n","        for i, (x_batch, y_batch) in enumerate(data_loader):\n","            self.optimizer.zero_grad()\n","\n","            x_batch = x_batch.to(self.device)\n","            y_batch = y_batch.to(self.device)\n","\n","            y_pred = self.model(x_batch)\n","\n","            # ResNets do not have an NFE attribute\n","            if not self.is_resnet:\n","                iteration_nfes = self._get_and_reset_nfes()\n","                epoch_nfes += iteration_nfes\n","\n","            loss = self.loss_func(y_pred, y_batch)\n","            loss.backward()\n","            self.optimizer.step()\n","            epoch_loss += loss.item()\n","\n","            if not self.is_resnet:\n","                iteration_backward_nfes = self._get_and_reset_nfes()\n","                epoch_backward_nfes += iteration_backward_nfes\n","\n","            self.steps += 1\n","\n","        # Record epoch mean information\n","        return epoch_loss / len(data_loader)\n","\n","    def _get_and_reset_nfes(self):\n","        \"\"\"Returns and resets the number of function evaluations for model.\"\"\"\n","        if hasattr(self.model, 'odeblock'):  # If we are using ODENet\n","            iteration_nfes = self.model.odeblock.odefunc.nfe\n","            # Set nfe count to 0 before backward pass, so we can\n","            # also measure backwards nfes\n","            self.model.odeblock.odefunc.nfe = 0\n","        else:  # If we are using ODEBlock\n","            iteration_nfes = self.model.odefunc.nfe\n","            self.model.odefunc.nfe = 0\n","        return iteration_nfes"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_1WyaoNy1qGo"},"source":["#### previous version"]},{"cell_type":"markdown","metadata":{"id":"7DdIyvIazkyX"},"source":["### Declare simulated Args Class [contain learning rate and momentum coeff]"]},{"cell_type":"code","metadata":{"id":"qHwEddJ_AEBq","executionInfo":{"status":"ok","timestamp":1638821970965,"user_tz":300,"elapsed":10,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["class SimulatedArgs():\n","    def __init__(self, epochs, batch_size, optimizer, dry_run, lr_AdaDelta=1, lr_SGD=0.1, momentum=0.9, lr_Adam = 0.001):\n","        # Training settings\n","        self.epochs = epochs\n","\n","        self.batch_size = batch_size  # or 128 [later]\n","        self.test_batch_size = 1000\n","        self.no_cuda = False\n","        \n","        self.optimizer = optimizer\n","          # for AdaDelta optimizer\n","        if (self.optimizer == \"AdaDelta\"):\n","          self.lr = lr_AdaDelta\n","        elif (self.optimizer == \"SGD\"):\n","          # for SGD optimizer\n","          self.lr_SGD = lr_SGD\n","          self.momentum_SGD = 0.9\n","        elif (self.optimizer == \"Adam\"):\n","          self.lr_Adam = lr_Adam\n","\n","        self.gamma = 0.7\n","        self.seed = 1\n","\n","        self.log_interval = 10\n","        self.dry_run = dry_run\n","        self.save_model = False\n","\n","        # # Lists for visualization of loss and accuracy \n","        # self.loss_list = []\n","        # self.iteration_list = []\n","        # self.accuracy_list = []\n","\n","        # # Lists for knowing classwise accuracy\n","        # self.predictions_list = []\n","        # self.labels_list = []"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"vvDv2ZeE7rJF","executionInfo":{"status":"ok","timestamp":1638821970966,"user_tz":300,"elapsed":10,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["def main(args, dataset1, dataset2, hidden_dim):\n","  use_cuda = not args.no_cuda and torch.cuda.is_available()\n","\n","  torch.manual_seed(args.seed)\n","\n","  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","  train_kwargs = {'batch_size': args.batch_size}\n","  test_kwargs = {'batch_size': args.test_batch_size}\n","  if use_cuda:\n","      cuda_kwargs = {'num_workers': 1,\n","                      'pin_memory': True,\n","                      'shuffle': True}\n","      train_kwargs.update(cuda_kwargs)\n","      test_kwargs.update(cuda_kwargs)\n","\n","\n","  train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n","  test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n","\n","  # model = ResNet(data_dim = 28*28*1, hidden_dim = hidden_dim , num_layers = 5, output_dim=10, is_img=True)\n","  model = Net()\n","  model.to(device)\n","\n","  ## ---------------------------- IMPORTANT ----------------------------------\n","  # choose correct optimizer\n","  print('\\nTraining SetUp: batch size: {}, optimizer: {} \\n'.format(args.batch_size, args.optimizer))\n","  if (args.optimizer == \"AdaDelta\"):\n","    print('Inner Parameters: lr: {} \\n'.format(args.lr))\n","    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n","\n","  elif (args.optimizer == \"SGD\"):\n","    print('Inner Parameters: lr_SGD: {}, momentum_SGD: {} \\n'.format(args.lr_SGD, args.momentum_SGD))\n","    optimizer = optim.SGD(model.parameters(), lr=args.lr_SGD, momentum=args.momentum_SGD)\n","  elif (args.optimizer == \"Adam\"):\n","    print('Inner Parameters: lr_Adam: {} \\n'.format(args.lr_Adam))\n","    optimizer = optim.Adam(model.parameters(), lr=args.lr_Adam)\n","\n","\n","\n","  # set linear rate updater\n","  # scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n","\n","\n","  trainer = Trainer(model, optimizer, device, classification=True)\n","\n","  ## ---------------------------- IMPORTANT ----------------------------------\n","  trainer.train(train_loader, args.epochs, device, test_loader)\n","\n"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-bk7BZ_UzSf9"},"source":["### Start Testing!!!"]},{"cell_type":"markdown","metadata":{"id":"XA7VBwDX-be8"},"source":["#### Choose the inner hidden dimension as 128 [Standard Model]"]},{"cell_type":"markdown","metadata":{"id":"E4ktQAak_uZg"},"source":["##### Figure out the approximate size (num of parameter) of the Toy example from Pytorch offical github (some CNN)\n","\n","Then adjust the hidden dim of our ResNet to have similar trainable parameter\n"]},{"cell_type":"code","metadata":{"id":"gfnaIpxFAovc","scrolled":true,"executionInfo":{"status":"ok","timestamp":1638821970966,"user_tz":300,"elapsed":9,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["# class Net(nn.Module):\n","#     def __init__(self):\n","#         super(Net, self).__init__()\n","#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n","#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","#         self.dropout1 = nn.Dropout(0.25)\n","#         self.dropout2 = nn.Dropout(0.5)\n","#         self.fc1 = nn.Linear(9216, 128)\n","#         self.fc2 = nn.Linear(128, 10)\n","\n","#     def forward(self, x):\n","#         x = self.conv1(x)\n","#         x = F.relu(x)\n","#         x = self.conv2(x)\n","#         x = F.relu(x)\n","#         x = F.max_pool2d(x, 2)\n","#         x = self.dropout1(x)\n","#         x = torch.flatten(x, 1)\n","#         x = self.fc1(x)\n","#         x = F.relu(x)\n","#         x = self.dropout2(x)\n","#         x = self.fc2(x)\n","#         output = F.log_softmax(x, dim=1)\n","#         return output\n","\n","\n","# for data, target in dataset2:\n","#   pass\n","# # x = torch.randn(1,1,32,32)\n","# x = data.shape\n","# print(x)\n","# model = Net()\n","# # model = ResNet(data_dim = 28*28*1, hidden_dim = 128 , num_layers = 5, output_dim=10, is_img=True)\n","# if torch.cuda.is_available():\n","#     model.cuda()\n","# summary(model,(1,28,28))\n","\n","# model = ResNet(data_dim = 28*28*1, hidden_dim = 128 , num_layers = 5, output_dim=10, is_img=True)\n","# if torch.cuda.is_available():\n","#     model.cuda()\n","# summary(model,(1,28,28))"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mJytEEaaAs8C"},"source":["### Start our testing with hidden_dim = 128"]},{"cell_type":"markdown","metadata":{"id":"BrAWP8DtDpoy"},"source":["#### SGD -- (batch_size = 128)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"pRjsBwQ8G00n","scrolled":true,"executionInfo":{"status":"error","timestamp":1638822005429,"user_tz":300,"elapsed":371,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}},"outputId":"f31b75d3-75cf-4bf5-b80a-63ebcf8cdceb"},"source":["# [1] Training SetUp: batch size: 128, optimizer: SGD \n","args = SimulatedArgs(epochs=50, batch_size=128, optimizer = \"Adam\", dry_run = False)\n","main(args, trainset_1, dataset2, hidden_dim = 128)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training SetUp: batch size: 128, optimizer: Adam \n","\n","Inner Parameters: lr_Adam: 0.001 \n","\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-49eec6a8027e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# [1] Training SetUp: batch size: 128, optimizer: SGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimulatedArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-28-90ea90c7245d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, dataset1, dataset2, hidden_dim)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m## ---------------------------- IMPORTANT ----------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-223dbc3aad16>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, num_epochs, device, test_loader)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-223dbc3aad16>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# ResNets do not have an NFE attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_resnet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0miteration_nfes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_and_reset_nfes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mepoch_nfes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0miteration_nfes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-223dbc3aad16>\u001b[0m in \u001b[0;36m_get_and_reset_nfes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0modeblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0modefunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# If we are using ODEBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0miteration_nfes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0modefunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0modefunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miteration_nfes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'odefunc'"]}]},{"cell_type":"code","metadata":{"id":"1sEfrJJmZZoo","executionInfo":{"status":"aborted","timestamp":1638821971113,"user_tz":300,"elapsed":152,"user":{"displayName":"Ziang Cao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06112844750422656704"}}},"source":["args = SimulatedArgs(epochs=50, batch_size=128, optimizer = \"Adam\", dry_run = False)\n","main(args, trainloader_1, dataset2, hidden_dim = 128)"],"execution_count":null,"outputs":[]}]}